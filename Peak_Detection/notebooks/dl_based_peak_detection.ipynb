{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "DATA_PATH = '/Users/mpekey/Desktop/FlyVideo/Peak_Signal_Data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "2D Sequence Data after concatenating features\n",
    "\n",
    "Data Shape: (num_examples, features, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_peak_fn = os.path.join(DATA_PATH, 'true_peak_annotations.npy')\n",
    "false_peak_fn = os.path.join(DATA_PATH, 'false_peak_annotations.npy')\n",
    "\n",
    "true_peak_annotations_array = np.load(true_peak_fn)\n",
    "false_peak_annotations_array = np.load(false_peak_fn, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True annotations shape: (2878, 60, 13) False annotations shape: (892, 60, 13)\n",
      "True labels shape: (2878,) False labels shape: (892,)\n",
      "Data shape after concatenation: (3770, 60, 13)\n",
      "Label shape after concatenation: (3770,)\n"
     ]
    }
   ],
   "source": [
    "true_annot_data = true_peak_annotations_array[:,:,:13]\n",
    "false_annot_data = false_peak_annotations_array[:,:,:13]\n",
    "\n",
    "true_annot_labels = np.ones((true_annot_data.shape[0],))\n",
    "false_annot_labels = np.zeros((false_annot_data.shape[0],))\n",
    "\n",
    "print('True annotations shape:',true_annot_data.shape, 'False annotations shape:', false_annot_data.shape)\n",
    "print('True labels shape:', true_annot_labels.shape, 'False labels shape:', false_annot_labels.shape)\n",
    "\n",
    "peaks_data = np.concatenate((true_annot_data, false_annot_data), axis = 0).astype('float64')\n",
    "peaks_labels = np.concatenate((true_annot_labels, false_annot_labels), axis = 0).astype('float64')\n",
    "print('Data shape after concatenation:', peaks_data.shape)\n",
    "print('Label shape after concatenation:', peaks_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Signal_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.peaks_data = torch.from_numpy(data).float()\n",
    "        self.peaks_labels = torch.from_numpy(labels).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.peaks_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.peaks_data[idx], self.peaks_labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(Signal_Dataset(peaks_data, peaks_labels),\n",
    "                                                                         [train_ratio, val_ratio, test_ratio])\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers = num_layers, batch_first = True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        h_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        # Initialize cell state\n",
    "        c_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        output, _ = self.lstm(x, (h_0, c_0))\n",
    "        # Index hidden state of last time step\n",
    "        return self.fc(output[:, -1, :]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM model architecture\n",
    "input_size = 13  # The number of features in the input (assuming each input sequence has 60 features)\n",
    "hidden_size = 128  # Number of hidden units in the LSTM\n",
    "output_size = 1  # The number of output classes (binary prediction)\n",
    "num_layers = 1\n",
    "\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the LSTM model\n",
    "model = LSTMModel(input_size, hidden_size, output_size, num_layers)\n",
    "\n",
    "# Move the model to the appropriate device (e.g., GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()  # Binary cross-entropy loss for binary classification\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,\n",
    "                train_loader,\n",
    "                val_loader,\n",
    "                optimizer,\n",
    "                criterion,\n",
    "                num_epochs):\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        val_loss = 0.0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.squeeze(), labels.float())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs.squeeze(), labels.float())\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        # Print the average loss after each epoch\n",
    "        average_train_loss = train_loss / len(train_loader)\n",
    "        average_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {average_train_loss:.4f}, Val Loss: {average_val_loss:.4f}\")\n",
    "\n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            loss = criterion(outputs.squeeze(), labels.float())\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            predicted = (torch.sigmoid(outputs) >= 0.5).float()\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted.squeeze() == labels.float()).sum().item()\n",
    "\n",
    "    average_test_loss = test_loss / len(loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Correct Predictions: {correct} among {total} data\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}%, Loss: {average_test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 0.5484, Val Loss: 0.5792\n",
      "Epoch [2/10], Train Loss: 0.5420, Val Loss: 0.5848\n",
      "Epoch [3/10], Train Loss: 0.5434, Val Loss: 0.5784\n",
      "Epoch [4/10], Train Loss: 0.5425, Val Loss: 0.5817\n",
      "Epoch [5/10], Train Loss: 0.5428, Val Loss: 0.5819\n",
      "Epoch [6/10], Train Loss: 0.5425, Val Loss: 0.5849\n",
      "Epoch [7/10], Train Loss: 0.5442, Val Loss: 0.5817\n",
      "Epoch [8/10], Train Loss: 0.5436, Val Loss: 0.5853\n",
      "Epoch [9/10], Train Loss: 0.5452, Val Loss: 0.5814\n",
      "Epoch [10/10], Train Loss: 0.5441, Val Loss: 0.5889\n"
     ]
    }
   ],
   "source": [
    "model, optimizer = train_model(model,\n",
    "                               train_loader,\n",
    "                               val_loader,\n",
    "                               optimizer,\n",
    "                               criterion,\n",
    "                               num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Predictions: 414 among 565 data\n",
      "Accuracy: 73.27%, Loss: 0.5889\n"
     ]
    }
   ],
   "source": [
    "eval_model(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
